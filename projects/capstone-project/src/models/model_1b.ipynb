{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PATHS\n",
    "\n",
    "TRAIN_FOLDER_PATH = '../../data/train/'\n",
    "VAL_FODLER_PATH = '../../data/validation/'\n",
    "TEST_FOLDER_PATH = '../../data/test/'\n",
    "PREVIEW_IMAGES_FOLDER = '../../data/preview/'\n",
    "\n",
    "TRAIN_CSV_PATH = '../../data/train_labels.csv'\n",
    "VALIDATION_CSV_PATH = '../../data/validation_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name used to save the weights in h5 format. The name match with the Jupyter notebook\n",
    "\n",
    "MODEL_NAME = 'model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_image_generator(inputPath, bs, lb, mode='train', aug=None):\n",
    "    # open the CSV file for reading\n",
    "    f = open(inputPath, \"r\")\n",
    "    \n",
    "    while True:\n",
    "        # initialize the batches of images and labels\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # keep looping until we reach the batch size\n",
    "        while len(images) < bs:\n",
    "            line = f.readline()\n",
    "            \n",
    "            # check if EOF\n",
    "            if line == \"\":\n",
    "                # reset the file pointer to the beginning of the file and re-read the line\n",
    "                f.seek(0)\n",
    "                line = f.readline()\n",
    "                \n",
    "                # if we are evaluating we should now break from our\n",
    "                # loop to ensure we don't continue to fill up the\n",
    "                # batch from samples at the beginning of the file\n",
    "                if mode == \"eval\":\n",
    "                    break\n",
    "                    \n",
    "            # extract the label and construct the image\n",
    "            line = line.strip().split(\",\")\n",
    "            label = line[1]\n",
    "            image = np.array([int(x) for x in line[0:]], dtype=\"uint8\")\n",
    "            image = image.reshape((64,64,3))\n",
    "            \n",
    "            # update the batches lists\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            # one-hot encode the labels\n",
    "            labels = lb.transform(np.array(labels))\n",
    "            \n",
    "            if aug is not None:\n",
    "                (images, labels) = next(aug.flow(np.array(images), labels, batch_size=bs))\n",
    "            \n",
    "            yield(np.array(images), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 75\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_TRAIN_IMAGES = 0\n",
    "NUM_VALIDATION_IMAGES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the training CSV file, then initialize the unique set of class\n",
    "# labels in the dataset along with the testing labels\n",
    "f = open(TRAIN_CSV_PATH, \"r\")\n",
    "labels = set()\n",
    "validationLabels = []\n",
    "\n",
    "for line in f:\n",
    "    label = line.strip().split(\",\")[1]\n",
    "    labels.add(label)\n",
    "    NUM_TRAIN_IMAGES += 1\n",
    "\n",
    "f.close()\n",
    "\n",
    "f = open(VALIDATION_CSV_PATH, \"r\")\n",
    "\n",
    "for line in f:\n",
    "    label = line.strip().split(\",\")[1]\n",
    "    validationLabels.append(label)\n",
    "    NUM_VALIDATION_IMAGES += 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the label binarizer for one-hot encoding labels, then encode\n",
    "# the testing labels\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(list(labels))\n",
    "validationLabels = lb.transform(validationLabels)\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range = 20, horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize both the training and validation image generators\n",
    "trainGen = csv_image_generator(TRAIN_CSV_PATH, BATCH_SIZE, lb, mode=\"train\", aug=aug)\n",
    "validationGen = csv_image_generator(VALIDATION_CSV_PATH, BATCH_SIZE, lb, mode=\"train\", aug=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the  model and compile it\n",
    "import architecure_1\n",
    "\n",
    "arc1 = architecure_1\n",
    "\n",
    "model = arc1.get_model()\n",
    "opt = SGD(lr=1e-2, momentum=0.9, decay=1e-2 / NUM_EPOCHS)\n",
    "model.compile(loss=\"categorial_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training w/ generator...\")\n",
    "H = model.fit_generator(trainGen,\n",
    "                       steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE,\n",
    "                       validation_data=validationGen,\n",
    "                       validation_steps=NUM_VALIDATION_IMAGES // BATCH_SIZE,\n",
    "                       epochs=NUM_EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
